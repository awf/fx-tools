{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/awf/awf-misc/blob/main/FX_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FX Experiments\n",
    "\n",
    "Some small experiments with torch.fx\n",
    "\n",
    "Some of these use the shnty code in this package, which is largely superseded by\n",
    "`ShapeProp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shnty_trace foo at (AbTensor[(3,5),torch.float32], abval[torch.float32], 2)\n",
      "shnty_trace -- x = x...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- b = b...abval[torch.float32]\n",
      "shnty_trace -- n = n...2\n",
      "shnty_trace -- mul = mul(b,x)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_1 = mul(float(1.234),x)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_2 = mul(mul_1,mul)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- relu = torch.relu(mul_2)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- neg = relu.neg()...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_3 = mul(float(1.234),neg)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_4 = mul(mul_3,mul)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- relu_1 = torch.relu(mul_4)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- neg_1 = relu_1.neg()...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- atan2 = torch.atan2(mul,neg_1)...AbTensor[(3,5),torch.float32]\n",
      "def foo(x,b,n):\n",
      "  v10 = x\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v11 = b\u001b[32m # $abval:abval[torch.float32]\u001b[0m\n",
      "  v12 = n\n",
      "  v13 = mul(v11,v10)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v14 = mul(float(1.234),v10)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v15 = mul(v14,v13)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v16 = torch.relu(v15)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v17 = v16.neg()\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v18 = mul(float(1.234),v17)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v19 = mul(v18,v13)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v20 = torch.relu(v19)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v21 = v20.neg()\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v22 = torch.atan2(v13,v21)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  return v22\n"
     ]
    }
   ],
   "source": [
    "from fx_shnty import shnty_trace, abstractify, AbstractTensor\n",
    "from fx_print import fx_print\n",
    "\n",
    "def aux(p, q):\n",
    "  return torch.relu(1.234 * p * q).neg()\n",
    "\n",
    "def foo(x, b, n):\n",
    "  y = b * x\n",
    "  for _ in range(n):  # Loops will be unrolled\n",
    "    x = aux(x, y)  # Function calls will be inlined\n",
    "  return torch.atan2(y, x)\n",
    "\n",
    "x = torch.randn(3,5)\n",
    "b = 8.2\n",
    "n = 2\n",
    "foo(x,b,n)\n",
    "\n",
    "foo_gm = shnty_trace(foo, (abstractify(x), abstractify(b), n))\n",
    "\n",
    "fx_print(foo_gm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shnty_trace foo at (AbTensor[(3,5),torch.float32], abval[torch.float32], 2)\n",
      "shnty_trace -- x = x...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- b = b...abval[torch.float32]\n",
      "shnty_trace -- n = n...2\n",
      "shnty_trace -- mul = mul(b,x)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_1 = mul(float(1.234),x)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_2 = mul(mul_1,mul)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- relu = torch.relu(mul_2)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- neg = relu.neg()...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_3 = mul(float(1.234),neg)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- mul_4 = mul(mul_3,mul)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- relu_1 = torch.relu(mul_4)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- neg_1 = relu_1.neg()...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- atan2 = torch.atan2(mul,neg_1)...AbTensor[(3,5),torch.float32]\n",
      "def foo(x,b,n):\n",
      "  v10 = x\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v11 = b\u001b[32m # $abval:abval[torch.float32]\u001b[0m\n",
      "  v12 = n\n",
      "  v13 = mul(v11,v10)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v14 = mul(float(1.234),v10)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v15 = mul(v14,v13)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v16 = torch.relu(v15)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v17 = v16.neg()\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v18 = mul(float(1.234),v17)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v19 = mul(v18,v13)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v20 = torch.relu(v19)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v21 = v20.neg()\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v22 = torch.atan2(v13,v21)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  return v22\n"
     ]
    }
   ],
   "source": [
    "# Suppose we didn't even want to build x:\n",
    "foo_gm = shnty_trace(foo, (AbstractTensor(torch.Size((3,5)), torch.float32), abstractify(b), n))\n",
    "\n",
    "fx_print(foo_gm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgQmrHBJDi2b",
    "outputId": "75caa67e-8d0c-42f0-8494-e2debc9294a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| _shnty_propagator_dict: {<built-in method cumsum of type object at 0x7ffae3cc5280>: <function fx_shnty_propagators._<shnty_propagator(function `cumsum`)> at 0x7ff9d9bfe7a0>,\n",
      "                             <built-in method neg of type object at 0x7ffae3cc5280>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd6c0>,\n",
      "                             <built-in method transpose of type object at 0x7ffae3cc5280>: <function fx_shnty_propagators._<shnty_propagator(function `transpose`)> at 0x7ff9d9bfe5c0>,\n",
      "                             <built-in method ones_like of type object at 0x7ffae3cc5280>: <function shnty_propagate_broadcast.<locals>.<"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda> at 0x7ff9d9bfd580>,\n",
      "                             <built-in method cos of type object at 0x7ffae3cc5280>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd800>,\n",
      "                             <built-in method relu of type object at 0x7ffae3cc5280>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd620>,\n",
      "                             <built-in method sin of type object at 0x7ffae3cc5280>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd760>,\n",
      "                             <built-in method sum of type object at 0x7ffae3cc5280>: <function fx_shnty_propagators._<shnty_propagator(function `sum`)> at 0x7ff9d9bfe700>,\n",
      "                             <built-in method trace of type object at 0x7ffae3cc5280>: <function fx_shnty_propagators._<shnty_propagator(function `torch.trace`)> at 0x7ff9d9bfe3e0>,\n",
      "                             <built-in method atan2 of type object at 0x7ffae3cc5280>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd300>,\n",
      "                             <built-in function add>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd440>,\n",
      "                             <built-in function mul>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd260>,\n",
      "                             <built-in function matmul>: <function fx_shnty_propagators._<shnty_propagator(function `matmul`)> at 0x7ff9d9bfe660>,\n",
      "                             <built-in function truediv>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd3a0>,\n",
      "                             <built-in function neg>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd4e0>,\n",
      "                             <built-in function getitem>: <function fx_shnty_propagators._<shnty_propagator(function `getitem`)> at 0x7ff9d9bfe480>,\n",
      "                             <built-in function eq>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdbc0>,\n",
      "                             <built-in function ne>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdc60>,\n",
      "                             <built-in function lt>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfda80>,\n",
      "                             <built-in function le>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdb20>,\n",
      "                             <built-in function gt>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdda0>,\n",
      "                             <built-in function ge>: <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdd00>,\n",
      "                             <function aux at 0x7ff9d897c360>: <function __main__._<shnty_propagator(function `__main__.aux`)> at 0x7ff9d897c680>,\n",
      "                             <function dropout at 0x7ffa2555da80>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.functional.dropout`)> at 0x7ff9d9bfe980>,\n",
      "                             <function embedding at 0x7ffa2555ed40>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.functional.embedding`)> at 0x7ff9d9bfeb60>,\n",
      "                             <function layer_norm at 0x7ffa2555f100>: <function layer_norm at 0x7ff9d9bfe840>,\n",
      "                             <attribute 'T' of 'torch._C.TensorBase' objects>: <function fx_shnty_propagators._<shnty_propagator(function `t`)> at 0x7ff9d9bfe520>,\n",
      "                             (<class 'torch.Tensor'>, 'cos'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd9e0>,\n",
      "                             (<class 'torch.Tensor'>, 'cumsum'): <function fx_shnty_propagators._<shnty_propagator(function `cumsum`)> at 0x7ff9d9bfe7a0>,\n",
      "                             (<class 'torch.Tensor'>, 'eq'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdf80>,\n",
      "                             (<class 'torch.Tensor'>, 'ge'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfe0c0>,\n",
      "                             (<class 'torch.Tensor'>, 'gt'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfe160>,\n",
      "                             (<class 'torch.Tensor'>, 'le'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfdee0>,\n",
      "                             (<class 'torch.Tensor'>, 'long'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfe200>,\n",
      "                             (<class 'torch.Tensor'>, 'lt'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfde40>,\n",
      "                             (<class 'torch.Tensor'>, 'matmul'): <function fx_shnty_propagators._<shnty_propagator(function `matmul`)> at 0x7ff9d9bfe660>,\n",
      "                             (<class 'torch.Tensor'>, 'ne'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfe020>,\n",
      "                             (<class 'torch.Tensor'>, 'neg'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd8a0>,\n",
      "                             (<class 'torch.Tensor'>, 'reshape'): <function fx_shnty_propagators._<shnty_propagator(function `reshape`)> at 0x7ff9d9bfe340>,\n",
      "                             (<class 'torch.Tensor'>, 'sin'): <function shnty_propagate_broadcast.<locals>.<lambda> at 0x7ff9d9bfd940>,\n",
      "                             (<class 'torch.Tensor'>, 'sum'): <function fx_shnty_propagators._<shnty_propagator(function `sum`)> at 0x7ff9d9bfe700>,\n",
      "                             (<class 'torch.Tensor'>, 't'): <function fx_shnty_propagators._<shnty_propagator(function `t`)> at 0x7ff9d9bfe520>,\n",
      "                             (<class 'torch.Tensor'>, 'transpose'): <function fx_shnty_propagators._<shnty_propagator(function `transpose`)> at 0x7ff9d9bfe5c0>,\n",
      "                             <class 'torch.nn.modules.linear.Linear'>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.modules.linear.Linear`)> at 0x7ff9d9bfec00>,\n",
      "                             <class 'torch.nn.modules.activation.ReLU'>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.modules.activation.ReLU`)> at 0x7ff9d9bfeca0>,\n",
      "                             <class 'torch.nn.modules.dropout.Dropout'>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.modules.normalization.LayerNorm`)> at 0x7ff9d9bfe8e0>,\n",
      "                             <class 'torch.nn.modules.normalization.LayerNorm'>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.modules.normalization.LayerNorm`)> at 0x7ff9d9bfe8e0>,\n",
      "                             <class 'torch.nn.modules.sparse.Embedding'>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.modules.sparse.Embedding`)> at 0x7ff9d9bfeac0>,\n",
      "                             <class 'torch.nn.modules.transformer.TransformerEncoder'>: <function fx_shnty_propagators._<shnty_propagator(function `torch.nn.modules.transformer.TransformerEncoder`)> at 0x7ff9d9bfea20>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shnty_trace foo at (AbTensor[(3,5),torch.float32], abval[torch.float32], 2)\n",
      "shnty_trace -- x = x...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- b = b...abval[torch.float32]\n",
      "shnty_trace -- n = n...2\n",
      "shnty_trace -- mul = mul(b,x)...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- aux = __main__.aux(x,mul)\u001b[32m # [/tmp/ipykernel_1580975/1924174572.py:5]\u001b[0m...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- aux_1 = __main__.aux(aux,mul)\u001b[32m # [/tmp/ipykernel_1580975/1924174572.py:5]\u001b[0m...AbTensor[(3,5),torch.float32]\n",
      "shnty_trace -- atan2 = torch.atan2(mul,aux_1)...AbTensor[(3,5),torch.float32]\n",
      "def foo(x,b,n):\n",
      "  v10 = x\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v11 = b\u001b[32m # $abval:abval[torch.float32]\u001b[0m\n",
      "  v12 = n\n",
      "  v13 = mul(v11,v10)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  v14 = __main__.aux(v10,v13)\u001b[32m # $abval:AbTensor[(3,5),torch.float32],is_wrapped:True[/tmp/ipykernel_1580975/1924174572.py:5]\u001b[0m\n",
      "  v15 = __main__.aux(v14,v13)\u001b[32m # $abval:AbTensor[(3,5),torch.float32],is_wrapped:True[/tmp/ipykernel_1580975/1924174572.py:5]\u001b[0m\n",
      "  v16 = torch.atan2(v13,v15)\u001b[32m # $abval:AbTensor[(3,5),torch.float32]\u001b[0m\n",
      "  return v16\n"
     ]
    }
   ],
   "source": [
    "from torch import fx\n",
    "from fx_shnty import shnty_trace, abstractify, shnty_propagator, AbstractTensor, _shnty_propagator_dict\n",
    "from fx_print import fx_print\n",
    "\n",
    "def aux(p, q):\n",
    "  return torch.relu(1.234 * p * q).neg()\n",
    "\n",
    "aux = fx.wrap(aux)\n",
    "\n",
    "@shnty_propagator(aux)\n",
    "def _(p_abval, q_abval):\n",
    "  return p_abval\n",
    "\n",
    "\n",
    "from icecream import ic\n",
    "ic(_shnty_propagator_dict)\n",
    "\n",
    "def foo(x, b, n):\n",
    "  y = b * x\n",
    "  for _ in range(n):  # Loops will be unrolled\n",
    "    x = aux(x, y)  # Function calls will be inlined\n",
    "  return torch.atan2(y, x)\n",
    "\n",
    "x = torch.randn(3,5)\n",
    "b = 8.2\n",
    "n = 2\n",
    "foo(x,b,n)\n",
    "\n",
    "foo_gm = shnty_trace(foo, (abstractify(x), abstractify(b), n))\n",
    "\n",
    "fx_print(foo_gm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: convert relu to gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oaclgwPxDnvh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def my_func(x):\n",
      "  v10 = x\n",
      "  v11 = torch._C._nn.gelu(v10)\n",
      "  v12 = add(v11,v10)\n",
      "  return v12\n"
     ]
    }
   ],
   "source": [
    "def my_func(x):\n",
    "    return torch.relu(x) + x\n",
    "\n",
    "def relu_to_gelu(mod: torch.fx.GraphModule):\n",
    "    g = mod.graph\n",
    "    for n in g.nodes:\n",
    "        if n.op == 'call_function' and n.target == torch.relu:\n",
    "            n.target = torch.nn.functional.gelu\n",
    "\n",
    "    mod.recompile()\n",
    "    return None # in-place modification of the graph\n",
    "\n",
    "my_func_trace = torch.fx.symbolic_trace(my_func)\n",
    "relu_to_gelu(my_func_trace)\n",
    "fx_print(my_func_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to functions\n",
    "\n",
    "Why _do_ we distinguish methods and functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: contains t.neg()\n",
      "def my_func(x):\n",
      "  v10 = x\n",
      "  v11 = v10.neg()\n",
      "  v12 = torch.relu(v11)\n",
      "  v13 = add(v12,v10)\n",
      "  return v13\n",
      "method_to_function: replacing <method 'neg' of 'torch._C.TensorBase' objects> in neg = x.neg()\u001b[32m # Tensor[3, torch.float32]\u001b[0m\n",
      "Modified: contains torch.neg(t)\n",
      "def my_func(x):\n",
      "  v10 = x\u001b[32m # Tensor[3, torch.float32]\u001b[0m\n",
      "  v11 = torch.neg(v10)\n",
      "  v12 = torch.relu(v11)\u001b[32m # Tensor[3, torch.float32]\u001b[0m\n",
      "  v13 = add(v12,v10)\u001b[32m # Tensor[3, torch.float32]\u001b[0m\n",
      "  return v13\u001b[32m # Tensor[3, torch.float32]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from fx_print import fx_print_node\n",
    "from difffx import fx_type, fx_add_shapes\n",
    "\n",
    "\n",
    "def my_func(x):\n",
    "    return torch.relu(x.neg()) + x\n",
    "\n",
    "\n",
    "print(\"Original: contains t.neg()\")\n",
    "fx_print(torch.fx.symbolic_trace(my_func))\n",
    "\n",
    "\n",
    "# map from method to function\n",
    "def method_to_function(\n",
    "    mod: torch.fx.GraphModule,\n",
    "    replacements={torch.Tensor.neg: torch.neg},\n",
    "    verbose=False,\n",
    "):\n",
    "    g = mod.graph\n",
    "    for n in g.nodes:\n",
    "        if n.op == \"call_method\":\n",
    "            # create IR to call new activate\n",
    "            with g.inserting_after(n):\n",
    "                ty = n.meta[\"type\"]\n",
    "                key = getattr(ty, n.target)\n",
    "                if key in replacements:\n",
    "                    print(f\"method_to_function: replacing {key} in\", fx_print_node(n))\n",
    "                    new_n = g.call_function(replacements[key], n.args)\n",
    "                    n.replace_all_uses_with(new_n)\n",
    "                    g.erase_node(n)\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"key not in fn [{key}]\", fx_print_node(n))\n",
    "\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"doing nothing to\", fx_print_node(n))\n",
    "\n",
    "    mod.recompile()\n",
    "    return None  # in-place modification of the graph\n",
    "\n",
    "\n",
    "my_func_trace = torch.fx.symbolic_trace(my_func)\n",
    "fx_add_shapes(my_func_trace, torch.zeros((2, 3)))\n",
    "method_to_function(my_func_trace)\n",
    "\n",
    "print(\"Modified: contains torch.neg(t)\")\n",
    "fx_print(my_func_trace)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMk6IojwKPOoEtWLs82Civ+",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "awfutils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
